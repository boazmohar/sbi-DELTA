{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SBI-DELTA: Simulation-Based Inference for Multiplexed Fluorescence Microscopy\n",
    "\n",
    "This notebook demonstrates how to use the improved multiplex_sim package for simulation-based inference of fluorophore concentrations in multiplexed microscopy experiments.\n",
    "\n",
    "## Overview\n",
    "\n",
    "The SBI-DELTA approach addresses the challenge of inferring fluorophore concentrations from multiplexed microscopy data where:\n",
    "- Multiple fluorophores have overlapping spectra\n",
    "- Detection channels have limited spectral resolution\n",
    "- Photon noise and background fluorescence complicate measurements\n",
    "\n",
    "We use simulation-based inference (SBI) to learn the relationship between fluorophore concentrations and detected signals."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "from pathlib import Path\n",
    "\n",
    "# Import our improved multiplex_sim package\n",
    "import sys\n",
    "sys.path.append('..')\n",
    "\n",
    "from multiplex_sim import (\n",
    "    # Core simulation\n",
    "    list_fluorophores, plot_fluorophores,\n",
    "    \n",
    "    # SBI components\n",
    "    SBIConfig, SBISimulator, create_sbi_simulator,\n",
    "    TrainingConfig, ExperimentConfig, SBITrainer, run_sbi_experiment\n",
    ")\n",
    "\n",
    "# Set up plotting\n",
    "plt.style.use('default')\n",
    "plt.rcParams['figure.figsize'] = (10, 6)\n",
    "plt.rcParams['font.size'] = 12"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Explore Available Fluorophores\n",
    "\n",
    "First, let's see what fluorophores we have available and visualize their spectra."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List available fluorophores\n",
    "available_fluors = list_fluorophores(\"../data/spectra_npz\")\n",
    "print(f\"Available fluorophores ({len(available_fluors)}):\")\n",
    "for i, name in enumerate(available_fluors):\n",
    "    print(f\"  {i+1:2d}. {name}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select a subset of fluorophores for our experiment\n",
    "# Choose fluorophores with good spectral separation\n",
    "selected_fluors = ['JF525', 'JF552', 'JF608', 'JFX673', 'JF722']\n",
    "\n",
    "print(f\"Selected fluorophores for multiplexing: {selected_fluors}\")\n",
    "\n",
    "# Plot their spectra\n",
    "plot_fluorophores(selected_fluors, \"../data/spectra_npz\", normalize=True)\n",
    "plt.title(\"Selected Fluorophore Spectra\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Configure the SBI Simulation\n",
    "\n",
    "Now we'll set up the simulation parameters and create an SBI simulator."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configure SBI simulation parameters\n",
    "sbi_config = SBIConfig(\n",
    "    wavelength_range=(500, 800),  # Focus on visible range\n",
    "    wavelength_step=1.0,\n",
    "    total_dye_photons=300.0,      # Photon budget for dyes\n",
    "    total_background_photons=30.0, # Background fluorescence\n",
    "    filter_type=\"sigmoid\",        # Use sigmoid filters\n",
    "    edge_steepness=1.0,\n",
    "    background_fluorophore=\"NADH\",\n",
    "    random_seed=42\n",
    ")\n",
    "\n",
    "print(\"SBI Configuration:\")\n",
    "print(f\"  Wavelength range: {sbi_config.wavelength_range} nm\")\n",
    "print(f\"  Dye photon budget: {sbi_config.total_dye_photons}\")\n",
    "print(f\"  Background photons: {sbi_config.total_background_photons}\")\n",
    "print(f\"  Filter type: {sbi_config.filter_type}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create SBI simulator\n",
    "simulator = create_sbi_simulator(\n",
    "    fluorophore_names=selected_fluors,\n",
    "    spectra_dir=\"../data/spectra_npz\",\n",
    "    config=sbi_config\n",
    ")\n",
    "\n",
    "print(f\"Created SBI simulator for {len(selected_fluors)} fluorophores\")\n",
    "print(f\"Loaded spectra: {list(simulator.emission_spectra.keys())}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Design Detection Filter Configuration\n",
    "\n",
    "We need to design a set of detection filters that can distinguish between our fluorophores."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Design detection filters\n",
    "# We'll use 4 channels to detect 5 fluorophores (challenging but realistic)\n",
    "center_wavelengths = [540, 580, 620, 680]  # Channel centers\n",
    "bandwidths = [25, 25, 25, 30]              # Channel bandwidths\n",
    "\n",
    "print(f\"Detection configuration:\")\n",
    "print(f\"  Number of channels: {len(center_wavelengths)}\")\n",
    "print(f\"  Center wavelengths: {center_wavelengths} nm\")\n",
    "print(f\"  Bandwidths: {bandwidths} nm\")\n",
    "\n",
    "# Visualize the filter configuration\n",
    "wavelengths = np.arange(500, 800, 1)\n",
    "filters = simulator.filter_bank.create_filters(center_wavelengths, bandwidths)\n",
    "\n",
    "plt.figure(figsize=(12, 6))\n",
    "for i, (center, bandwidth) in enumerate(zip(center_wavelengths, bandwidths)):\n",
    "    plt.plot(wavelengths, filters[i], label=f'Channel {i+1} ({center} nm)', linewidth=2)\n",
    "\n",
    "plt.xlabel('Wavelength (nm)')\n",
    "plt.ylabel('Filter Transmission')\n",
    "plt.title('Detection Filter Configuration')\n",
    "plt.legend()\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Test the Simulator\n",
    "\n",
    "Let's test our simulator with some example fluorophore concentrations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create some test concentration combinations\n",
    "test_concentrations = np.array([\n",
    "    [0.3, 0.2, 0.1, 0.2, 0.2],  # Mixed combination\n",
    "    [1.0, 0.0, 0.0, 0.0, 0.0],  # Only JF525\n",
    "    [0.0, 1.0, 0.0, 0.0, 0.0],  # Only JF552\n",
    "    [0.0, 0.0, 0.0, 0.0, 1.0],  # Only JF722\n",
    "    [0.2, 0.2, 0.2, 0.2, 0.2],  # Equal mixture\n",
    "])\n",
    "\n",
    "# Simulate detected signals\n",
    "detected_signals = simulator.simulate_batch(\n",
    "    test_concentrations,\n",
    "    center_wavelengths,\n",
    "    bandwidths,\n",
    "    add_noise=True\n",
    ")\n",
    "\n",
    "print(\"Test simulation results:\")\n",
    "print(\"Concentrations -> Detected signals\")\n",
    "for i, (conc, signal) in enumerate(zip(test_concentrations, detected_signals)):\n",
    "    print(f\"Test {i+1}: {conc} -> {signal.numpy()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize the relationship between concentrations and signals\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 5))\n",
    "\n",
    "# Plot concentrations\n",
    "im1 = ax1.imshow(test_concentrations.T, aspect='auto', cmap='viridis')\n",
    "ax1.set_title('Input Concentrations')\n",
    "ax1.set_xlabel('Test Case')\n",
    "ax1.set_ylabel('Fluorophore')\n",
    "ax1.set_yticks(range(len(selected_fluors)))\n",
    "ax1.set_yticklabels(selected_fluors)\n",
    "plt.colorbar(im1, ax=ax1, label='Concentration')\n",
    "\n",
    "# Plot detected signals\n",
    "im2 = ax2.imshow(detected_signals.numpy().T, aspect='auto', cmap='plasma')\n",
    "ax2.set_title('Detected Signals')\n",
    "ax2.set_xlabel('Test Case')\n",
    "ax2.set_ylabel('Detection Channel')\n",
    "ax2.set_yticks(range(len(center_wavelengths)))\n",
    "ax2.set_yticklabels([f'Ch{i+1} ({w}nm)' for i, w in enumerate(center_wavelengths)])\n",
    "plt.colorbar(im2, ax=ax2, label='Photon Count')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Train SBI Model\n",
    "\n",
    "Now we'll train a neural posterior estimator to learn the inverse mapping from detected signals to fluorophore concentrations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configure training parameters\n",
    "training_config = TrainingConfig(\n",
    "    n_training_samples=5000,      # Number of training samples\n",
    "    n_validation_samples=500,     # Number of validation samples\n",
    "    hidden_features=64,           # Neural network size\n",
    "    num_transforms=8,             # Number of normalizing flow layers\n",
    "    learning_rate=1e-3,           # Learning rate\n",
    "    training_batch_size=100,      # Batch size\n",
    "    max_num_epochs=100,           # Maximum training epochs\n",
    "    stop_after_epochs=15,         # Early stopping patience\n",
    "    device=\"cpu\"                  # Use CPU (change to \"cuda\" if available)\n",
    ")\n",
    "\n",
    "print(\"Training Configuration:\")\n",
    "print(f\"  Training samples: {training_config.n_training_samples}\")\n",
    "print(f\"  Validation samples: {training_config.n_validation_samples}\")\n",
    "print(f\"  Network size: {training_config.hidden_features} hidden features\")\n",
    "print(f\"  Max epochs: {training_config.max_num_epochs}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create experiment configuration\n",
    "experiment_config = ExperimentConfig(\n",
    "    fluorophore_names=selected_fluors,\n",
    "    spectra_dir=\"../data/spectra_npz\",\n",
    "    center_wavelengths=center_wavelengths,\n",
    "    bandwidths=bandwidths,\n",
    "    prior_type=\"dirichlet\",  # Use Dirichlet prior for concentration ratios\n",
    "    prior_params={\"concentration\": 1.0},\n",
    "    sbi_config=sbi_config,\n",
    "    training_config=training_config,\n",
    "    experiment_name=\"5_fluor_4_channel_experiment\",\n",
    "    description=\"5 fluorophores detected with 4 channels using Dirichlet prior\"\n",
    ")\n",
    "\n",
    "print(f\"Experiment: {experiment_config.experiment_name}\")\n",
    "print(f\"Description: {experiment_config.description}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create and train SBI model\n",
    "print(\"Creating SBI trainer...\")\n",
    "trainer = SBITrainer(experiment_config)\n",
    "\n",
    "print(\"Setting up prior distribution...\")\n",
    "prior = trainer.setup_prior()\n",
    "print(f\"Prior type: {type(prior).__name__}\")\n",
    "\n",
    "print(\"\\nGenerating training data...\")\n",
    "theta_train, x_train = trainer.generate_training_data()\n",
    "\n",
    "print(\"\\nGenerating validation data...\")\n",
    "theta_val, x_val = trainer.generate_validation_data()\n",
    "\n",
    "print(\"\\nTraining neural posterior estimator...\")\n",
    "posterior = trainer.train()\n",
    "\n",
    "print(\"\\nTraining completed!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Evaluate Model Performance\n",
    "\n",
    "Let's evaluate how well our trained model can recover fluorophore concentrations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate on validation data\n",
    "print(\"Evaluating model performance...\")\n",
    "validation_results = trainer.evaluate_on_validation(n_posterior_samples=100)\n",
    "\n",
    "print(\"\\nValidation Results Summary:\")\n",
    "print(f\"  Mean R²: {validation_results['mean_r_squared']:.3f} ± {validation_results['std_r_squared']:.3f}\")\n",
    "print(f\"  Median R²: {validation_results['median_r_squared']:.3f}\")\n",
    "\n",
    "print(\"\\nPer-fluorophore performance:\")\n",
    "for name in selected_fluors:\n",
    "    corr = validation_results.get(f\"{name}_correlation\", np.nan)\n",
    "    mae = validation_results.get(f\"{name}_mae\", np.nan)\n",
    "    print(f\"  {name}: correlation = {corr:.3f}, MAE = {mae:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot validation results\n",
    "true_params = validation_results['true_parameters']\n",
    "pred_params = validation_results['predicted_parameters']\n",
    "r_squared_values = validation_results['r_squared_values']\n",
    "\n",
    "fig, axes = plt.subplots(2, 3, figsize=(18, 10))\n",
    "axes = axes.flatten()\n",
    "\n",
    "# Plot true vs predicted for each fluorophore\n",
    "for i, name in enumerate(selected_fluors):\n",
    "    ax = axes[i]\n",
    "    \n",
    "    true_conc = true_params[:, i]\n",
    "    pred_conc = pred_params[:, i]\n",
    "    \n",
    "    # Scatter plot\n",
    "    ax.scatter(true_conc, pred_conc, alpha=0.6, s=20)\n",
    "    \n",
    "    # Perfect prediction line\n",
    "    max_val = max(true_conc.max(), pred_conc.max())\n",
    "    ax.plot([0, max_val], [0, max_val], 'r--', alpha=0.8, label='Perfect prediction')\n",
    "    \n",
    "    # Calculate correlation\n",
    "    valid_mask = ~(np.isnan(true_conc) | np.isnan(pred_conc))\n",
    "    if valid_mask.sum() > 1:\n",
    "        correlation = np.corrcoef(true_conc[valid_mask], pred_conc[valid_mask])[0, 1]\n",
    "    else:\n",
    "        correlation = np.nan\n",
    "    \n",
    "    ax.set_xlabel('True Concentration')\n",
    "    ax.set_ylabel('Predicted Concentration')\n",
    "    ax.set_title(f'{name}\\nCorrelation: {correlation:.3f}')\n",
    "    ax.grid(True, alpha=0.3)\n",
    "    ax.legend()\n",
    "\n",
    "# Plot R² distribution\n",
    "ax = axes[5]\n",
    "ax.hist(r_squared_values[~np.isnan(r_squared_values)], bins=20, alpha=0.7, edgecolor='black')\n",
    "ax.axvline(np.nanmean(r_squared_values), color='red', linestyle='--', \n",
    "           label=f'Mean: {np.nanmean(r_squared_values):.3f}')\n",
    "ax.set_xlabel('R² Value')\n",
    "ax.set_ylabel('Frequency')\n",
    "ax.set_title('R² Distribution')\n",
    "ax.legend()\n",
    "ax.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Analyze Multiplexing Capacity\n",
    "\n",
    "Let's analyze how well our current configuration can multiplex the selected fluorophores."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze multiplexing capacity\n",
    "print(\"Analyzing multiplexing capacity...\")\n",
    "capacity_results = trainer.analyze_multiplexing_capacity(\n",
    "    n_test_samples=1000,\n",
    "    r_squared_threshold=0.8\n",
    ")\n",
    "\n",
    "print(\"\\nMultiplexing Capacity Results:\")\n",
    "print(f\"  Configuration: {capacity_results['n_fluorophores']} fluorophores, {capacity_results['n_channels']} channels\")\n",
    "print(f\"  Samples with R² ≥ {capacity_results['r_squared_threshold']}: {capacity_results['good_performance_fraction']:.1%}\")\n",
    "print(f\"  Mean R²: {capacity_results['mean_r_squared']:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot multiplexing capacity analysis\n",
    "r2_dist = capacity_results['r_squared_distribution']\n",
    "threshold = capacity_results['r_squared_threshold']\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.hist(r2_dist[~np.isnan(r2_dist)], bins=30, alpha=0.7, edgecolor='black', label='R² Distribution')\n",
    "plt.axvline(threshold, color='red', linestyle='--', linewidth=2, label=f'Threshold (R² = {threshold})')\n",
    "plt.axvline(np.nanmean(r2_dist), color='orange', linestyle='--', linewidth=2, \n",
    "           label=f'Mean R² = {np.nanmean(r2_dist):.3f}')\n",
    "\n",
    "plt.xlabel('R² Value')\n",
    "plt.ylabel('Frequency')\n",
    "plt.title('Multiplexing Performance Distribution')\n",
    "plt.legend()\n",
    "plt.grid(True, alpha=0.3)\n",
    "\n",
    "# Add text box with summary statistics\n",
    "good_fraction = capacity_results['good_performance_fraction']\n",
    "textstr = f'Good Performance: {good_fraction:.1%}\\nMean R²: {np.nanmean(r2_dist):.3f}\\nMedian R²: {np.nanmedian(r2_dist):.3f}'\n",
    "props = dict(boxstyle='round', facecolor='wheat', alpha=0.8)\n",
    "plt.text(0.02, 0.98, textstr, transform=plt.gca().transAxes, fontsize=10,\n",
    "         verticalalignment='top', bbox=props)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Test on New Data\n",
    "\n",
    "Let's test our trained model on some new synthetic data to see how it performs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate new test data\n",
    "n_test = 10\n",
    "test_theta, test_x = trainer.simulator.generate_training_data(\n",
    "    n_samples=n_test,\n",
    "    center_wavelengths=center_wavelengths,\n",
    "    bandwidths=bandwidths,\n",
    "    prior_type=\"dirichlet\",\n",
    "    prior_params={\"concentration\": 1.0}\n",
    ")\n",
    "\n",
    "print(f\"Generated {n_test} test samples\")\n",
    "print(\"\\nTest data preview:\")\n",
    "print(\"True concentrations:\")\n",
    "for i in range(min(5, n_test)):\n",
    "    print(f\"  Sample {i+1}: {test_theta[i].numpy()}\")\n",
    "print(\"\\nDetected signals:\")\n",
    "for i in range(min(5, n_test)):\n",
    "    print(f\"  Sample {i+1}: {test_x[i].numpy()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make predictions on test data\n",
    "predictions = []\n",
    "uncertainties = []\n",
    "\n",
    "for i in range(n_test):\n",
    "    x_i = test_x[i]\n",
    "    \n",
    "    # Sample from posterior\n",
    "    samples = trainer.posterior.sample((200,), x=x_i, show_progress_bars=False).numpy()\n",
    "    \n",
    "    # Calculate mean and std\n",
    "    pred_mean = samples.mean(axis=0)\n",
    "    pred_std = samples.std(axis=0)\n",
    "    \n",
    "    predictions.append(pred_mean)\n",
    "    uncertainties.append(pred_std)\n",
    "\n",
    "predictions = np.array(predictions)\n",
    "uncertainties = np.array(uncertainties)\n",
    "\n",
    "print(\"Predictions with uncertainties:\")\n",
    "for i in range(n_test):\n",
    "    true_conc = test_theta[i].numpy()\n",
    "    pred_conc = predictions[i]\n",
    "    pred_unc = uncertainties[i]\n",
    "    \n",
    "    print(f\"\\nSample {i+1}:\")\n",
    "    print(f\"  True:      {true_conc}\")\n",
    "    print(f\"  Predicted: {pred_conc}\")\n",
    "    print(f\"  Std:       {pred_unc}\")\n",
    "    \n",
    "    # Calculate error\n",
    "    error = np.abs(true_conc - pred_conc)\n",
    "    print(f\"  Error:     {error}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize test results\n",
    "fig, axes = plt.subplots(2, 3, figsize=(18, 10))\n",
    "axes = axes.flatten()\n",
    "\n",
    "for i, name in enumerate(selected_fluors):\n",
    "    ax = axes[i]\n",
    "    \n",
    "    true_vals = test_theta[:, i].numpy()\n",
    "    pred_vals = predictions[:, i]\n",
    "    pred_errs = uncertainties[:, i]\n",
    "    \n",
    "    # Error bars plot\n",
    "    ax.errorbar(true_vals, pred_vals, yerr=pred_errs, fmt='o', capsize=5, alpha=0.7)\n",
    "    \n",
    "    # Perfect prediction line\n",
    "    max_val = max(true_vals.max(), pred_vals.max())\n",
    "    ax.plot([0, max_val], [0, max_val], 'r--', alpha=0.8, label='Perfect prediction')\n",
    "    \n",
    "    ax.set_xlabel('True Concentration')\n",
    "    ax.set_ylabel('Predicted Concentration')\n",
    "    ax.set_title(f'{name}')\n",
    "    ax.grid(True, alpha=0.3)\n",
    "    ax.legend()\n",
    "\n",
    "# Summary plot\n",
    "ax = axes[5]\n",
    "all_true = test_theta.numpy().flatten()\n",
    "all_pred = predictions.flatten()\n",
    "ax.scatter(all_true, all_pred, alpha=0.6)\n",
    "max_val = max(all_true.max(), all_pred.max())\n",
    "ax.plot([0, max_val], [0, max_val], 'r--', alpha=0.8, label='Perfect prediction')\n",
    "ax.set_xlabel('True Concentration')\n",
    "ax.set_ylabel('Predicted Concentration')\n",
    "ax.set_title('All Fluorophores Combined')\n",
    "ax.grid(True, alpha=0.3)\n",
    "ax.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Save the Experiment\n",
    "\n",
    "Finally, let's save our trained model and results for future use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the experiment\n",
    "save_dir = \"../experiments/5_fluor_4_channel_experiment\"\n",
    "trainer.save_experiment(save_dir)\n",
    "\n",
    "print(f\"Experiment saved to: {save_dir}\")\n",
    "print(\"\\nSaved files:\")\n",
    "save_path = Path(save_dir)\n",
    "if save_path.exists():\n",
    "    for file in save_path.iterdir():\n",
    "        print(f\"  - {file.name}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "In this notebook, we demonstrated the complete SBI-DELTA workflow:\n",
    "\n",
    "1. **Data Preparation**: Loaded and visualized fluorophore spectra\n",
    "2. **Simulation Setup**: Configured the SBI simulator with realistic parameters\n",
    "3. **Filter Design**: Designed detection filters for multiplexed imaging\n",
    "4. **Model Training**: Trained a neural posterior estimator using SBI\n",
    "5. **Performance Evaluation**: Assessed model performance on validation data\n",
    "6. **Capacity Analysis**: Analyzed the multiplexing capacity of our configuration\n",
    "7. **Testing**: Tested the model on new synthetic data\n",
    "8. **Persistence**: Saved the trained model for future use\n",
    "\n",
    "### Key Results\n",
    "\n",
    "- Successfully trained an SBI model to infer 5 fluorophore concentrations from 4 detection channels\n",
    "- Achieved reasonable performance with proper uncertainty quantification\n",
    "- Demonstrated the feasibility of multiplexed fluorescence microscopy with overlapping spectra\n",
    "\n",
    "### Next Steps\n",
    "\n",
    "- Experiment with different filter configurations\n",
    "- Try different prior distributions\n",
    "- Test with real experimental data\n",
    "- Optimize for specific experimental conditions\n",
    "- Explore active learning approaches for data-efficient training"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
