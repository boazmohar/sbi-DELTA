{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "94b3629d",
   "metadata": {},
   "source": [
    "# Parameter Sweep for Network Architectures: R² Improvement Analysis\n",
    "\n",
    "This notebook performs a parameter sweep over different network architectures and hyperparameters for the SBI Trainer, using synthetic spectra. The goal is to identify which settings yield the best R² improvements."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8dcd7ad4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Required Libraries\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import itertools\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "\n",
    "from sbi_delta.trainer import Trainer\n",
    "from sbi_delta.simulator.emission_simulator import EmissionSimulator\n",
    "from sbi_delta.spectra_manager import SpectraManager\n",
    "from sbi_delta.filter_bank import FilterBank\n",
    "from sbi_delta.config import BaseConfig, FilterConfig, ExcitationConfig\n",
    "from sbi_delta.excitation_manager import ExcitationManager"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7742129d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set Up Real Data and Configuration (matching sbi_hyperparameter_search.ipynb)\n",
    "import os\n",
    "base_path = os.path.abspath(\".\")\n",
    "fluorophore_names = [\"JF479\", \"JF525\", \"JF552\", \"JF608\", \"JFX650\", \"JFX673\"]\n",
    "\n",
    "config = BaseConfig(\n",
    "    min_wavelength=400,\n",
    "    max_wavelength=750,\n",
    "    wavelength_step=1,\n",
    "    spectra_folder=os.path.join(base_path, \"data/spectra_npz\"),\n",
    "    dye_names=fluorophore_names,\n",
    "    bg_dye='AF_v1',\n",
    "    photon_budget=1000,\n",
    ")\n",
    "filter_cfgs = [\n",
    "    FilterConfig(start, stop, sharpness=1)\n",
    "    for start, stop in zip([490, 530, 570, 620, 680], [530, 570, 620, 680, 740])\n",
    "]\n",
    "excitation_cfg = ExcitationConfig(excitation_mode=\"min_crosstalk\")\n",
    "spectra_manager = SpectraManager(config)\n",
    "spectra_manager.load()\n",
    "excitation_manager = ExcitationManager(config, excitation_cfg, spectra_manager)\n",
    "filter_bank = FilterBank(config, filter_cfgs)\n",
    "simulator = EmissionSimulator(\n",
    "    spectra_manager=spectra_manager,\n",
    "    filter_bank=filter_bank,\n",
    "    config=config,\n",
    "    excitation_manager=excitation_manager\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f20711ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total architecture parameter combinations: 18\n"
     ]
    }
   ],
   "source": [
    "# Define Architecture Parameter Sweep Grid\n",
    "# Sweep only over network architecture (density estimator, hidden features, num transforms)\n",
    "param_grid = {\n",
    "    'density_estimator': ['maf', 'nsf', 'mdn'],\n",
    "    'hidden_features': [32, 64, 128],\n",
    "    'num_transforms': [2, 4]\n",
    "}\n",
    "\n",
    "# Create all combinations\n",
    "keys, values = zip(*param_grid.items())\n",
    "param_combinations = [dict(zip(keys, v)) for v in itertools.product(*values)]\n",
    "print(f\"Total architecture parameter combinations: {len(param_combinations)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "631b3623",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running combination 1/18: {'density_estimator': 'maf', 'hidden_features': 32, 'num_transforms': 2}\n",
      " Neural network successfully converged after 125 epochs.\n",
      "        -------------------------\n",
      "        ||||| ROUND 1 STATS |||||:\n",
      "        -------------------------\n",
      "        Epochs trained: 125\n",
      "        Best validation performance: -7.4717\n",
      "        -------------------------\n",
      "        \n",
      "\n",
      "        -------------------------\n",
      "        ||||| ROUND 1 STATS |||||:\n",
      "        -------------------------\n",
      "        Epochs trained: 125\n",
      "        Best validation performance: -7.4717\n",
      "        -------------------------\n",
      "        \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validating: 100%|██████████| 500/500 [00:13<00:00, 37.22it/s]\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation mean R^2: 0.641, RMSE: 0.1131\n",
      "Running combination 2/18: {'density_estimator': 'maf', 'hidden_features': 32, 'num_transforms': 4}\n",
      " Neural network successfully converged after 102 epochs.\n",
      "        -------------------------\n",
      "        ||||| ROUND 1 STATS |||||:\n",
      "        -------------------------\n",
      "        Epochs trained: 102\n",
      "        Best validation performance: -7.4412\n",
      "        -------------------------\n",
      "        \n",
      "\n",
      "        -------------------------\n",
      "        ||||| ROUND 1 STATS |||||:\n",
      "        -------------------------\n",
      "        Epochs trained: 102\n",
      "        Best validation performance: -7.4412\n",
      "        -------------------------\n",
      "        \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validating: 100%|██████████| 500/500 [00:14<00:00, 35.28it/s]\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation mean R^2: 0.657, RMSE: 0.1209\n",
      "Running combination 3/18: {'density_estimator': 'maf', 'hidden_features': 64, 'num_transforms': 2}\n",
      " Neural network successfully converged after 128 epochs.\n",
      "        -------------------------\n",
      "        ||||| ROUND 1 STATS |||||:\n",
      "        -------------------------\n",
      "        Epochs trained: 128\n",
      "        Best validation performance: -7.4010\n",
      "        -------------------------\n",
      "        \n",
      "\n",
      "        -------------------------\n",
      "        ||||| ROUND 1 STATS |||||:\n",
      "        -------------------------\n",
      "        Epochs trained: 128\n",
      "        Best validation performance: -7.4010\n",
      "        -------------------------\n",
      "        \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validating: 100%|██████████| 500/500 [00:14<00:00, 35.29it/s]\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation mean R^2: 0.686, RMSE: 0.1205\n",
      "Running combination 4/18: {'density_estimator': 'maf', 'hidden_features': 64, 'num_transforms': 4}\n",
      " Neural network successfully converged after 154 epochs.\n",
      "        -------------------------\n",
      "        ||||| ROUND 1 STATS |||||:\n",
      "        -------------------------\n",
      "        Epochs trained: 154\n",
      "        Best validation performance: -6.8626\n",
      "        -------------------------\n",
      "        \n",
      "\n",
      "        -------------------------\n",
      "        ||||| ROUND 1 STATS |||||:\n",
      "        -------------------------\n",
      "        Epochs trained: 154\n",
      "        Best validation performance: -6.8626\n",
      "        -------------------------\n",
      "        \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validating: 100%|██████████| 500/500 [00:15<00:00, 31.75it/s]\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation mean R^2: 0.589, RMSE: 0.1360\n",
      "Running combination 5/18: {'density_estimator': 'maf', 'hidden_features': 128, 'num_transforms': 2}\n",
      " Neural network successfully converged after 184 epochs.\n",
      "        -------------------------\n",
      "        ||||| ROUND 1 STATS |||||:\n",
      "        -------------------------\n",
      "        Epochs trained: 184\n",
      "        Best validation performance: -7.6356\n",
      "        -------------------------\n",
      "        \n",
      "\n",
      "        -------------------------\n",
      "        ||||| ROUND 1 STATS |||||:\n",
      "        -------------------------\n",
      "        Epochs trained: 184\n",
      "        Best validation performance: -7.6356\n",
      "        -------------------------\n",
      "        \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validating: 100%|██████████| 500/500 [00:13<00:00, 36.24it/s]\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation mean R^2: 0.387, RMSE: 0.1242\n",
      "Running combination 6/18: {'density_estimator': 'maf', 'hidden_features': 128, 'num_transforms': 4}\n",
      " Neural network successfully converged after 100 epochs.\n",
      "        -------------------------\n",
      "        ||||| ROUND 1 STATS |||||:\n",
      "        -------------------------\n",
      "        Epochs trained: 100\n",
      "        Best validation performance: -7.2245\n",
      "        -------------------------\n",
      "        \n",
      "\n",
      "        -------------------------\n",
      "        ||||| ROUND 1 STATS |||||:\n",
      "        -------------------------\n",
      "        Epochs trained: 100\n",
      "        Best validation performance: -7.2245\n",
      "        -------------------------\n",
      "        \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validating: 100%|██████████| 500/500 [00:14<00:00, 33.86it/s]\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation mean R^2: 0.590, RMSE: 0.1206\n",
      "Running combination 7/18: {'density_estimator': 'nsf', 'hidden_features': 32, 'num_transforms': 2}\n",
      " Neural network successfully converged after 86 epochs.\n",
      "        -------------------------\n",
      "        ||||| ROUND 1 STATS |||||:\n",
      "        -------------------------\n",
      "        Epochs trained: 86\n",
      "        Best validation performance: -7.5807\n",
      "        -------------------------\n",
      "        \n",
      "\n",
      "        -------------------------\n",
      "        ||||| ROUND 1 STATS |||||:\n",
      "        -------------------------\n",
      "        Epochs trained: 86\n",
      "        Best validation performance: -7.5807\n",
      "        -------------------------\n",
      "        \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validating:   0%|          | 0/500 [00:00<?, ?it/s]/groups/spruston/home/moharb/mambaforge/envs/sbi_env/lib/python3.10/site-packages/nflows/transforms/lu.py:80: UserWarning: torch.triangular_solve is deprecated in favor of torch.linalg.solve_triangularand will be removed in a future PyTorch release.\n",
      "torch.linalg.solve_triangular has its arguments reversed and does not return a copy of one of the inputs.\n",
      "X = torch.triangular_solve(B, A).solution\n",
      "should be replaced with\n",
      "X = torch.linalg.solve_triangular(A, B). (Triggered internally at ../aten/src/ATen/native/BatchLinearAlgebra.cpp:2190.)\n",
      "  outputs, _ = torch.triangular_solve(\n",
      "Validating:   1%|          | 5/500 [00:00<00:11, 43.52it/s]/groups/spruston/home/moharb/mambaforge/envs/sbi_env/lib/python3.10/site-packages/nflows/transforms/lu.py:80: UserWarning: torch.triangular_solve is deprecated in favor of torch.linalg.solve_triangularand will be removed in a future PyTorch release.\n",
      "torch.linalg.solve_triangular has its arguments reversed and does not return a copy of one of the inputs.\n",
      "X = torch.triangular_solve(B, A).solution\n",
      "should be replaced with\n",
      "X = torch.linalg.solve_triangular(A, B). (Triggered internally at ../aten/src/ATen/native/BatchLinearAlgebra.cpp:2190.)\n",
      "  outputs, _ = torch.triangular_solve(\n",
      "Validating: 100%|██████████| 500/500 [00:11<00:00, 44.30it/s]\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation mean R^2: 0.605, RMSE: 0.1144\n",
      "Running combination 8/18: {'density_estimator': 'nsf', 'hidden_features': 32, 'num_transforms': 4}\n",
      " Neural network successfully converged after 92 epochs.\n",
      "        -------------------------\n",
      "        ||||| ROUND 1 STATS |||||:\n",
      "        -------------------------\n",
      "        Epochs trained: 92\n",
      "        Best validation performance: -7.4033\n",
      "        -------------------------\n",
      "        \n",
      "\n",
      "        -------------------------\n",
      "        ||||| ROUND 1 STATS |||||:\n",
      "        -------------------------\n",
      "        Epochs trained: 92\n",
      "        Best validation performance: -7.4033\n",
      "        -------------------------\n",
      "        \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validating:  77%|███████▋  | 385/500 [03:04<00:55,  2.09it/s]\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FAILED: {'density_estimator': 'nsf', 'hidden_features': 32, 'num_transforms': 4} with error: \n",
      "Running combination 9/18: {'density_estimator': 'nsf', 'hidden_features': 64, 'num_transforms': 2}\n",
      " Neural network successfully converged after 82 epochs.\n",
      "        -------------------------\n",
      "        ||||| ROUND 1 STATS |||||:\n",
      "        -------------------------\n",
      "        Epochs trained: 82\n",
      "        Best validation performance: -7.4813\n",
      "        -------------------------\n",
      "        \n",
      "\n",
      "        -------------------------\n",
      "        ||||| ROUND 1 STATS |||||:\n",
      "        -------------------------\n",
      "        Epochs trained: 82\n",
      "        Best validation performance: -7.4813\n",
      "        -------------------------\n",
      "        \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validating: 100%|██████████| 500/500 [00:11<00:00, 45.42it/s]\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation mean R^2: 0.642, RMSE: 0.1121\n",
      "Running combination 10/18: {'density_estimator': 'nsf', 'hidden_features': 64, 'num_transforms': 4}\n",
      " Neural network successfully converged after 87 epochs.\n",
      "        -------------------------\n",
      "        ||||| ROUND 1 STATS |||||:\n",
      "        -------------------------\n",
      "        Epochs trained: 87\n",
      "        Best validation performance: -7.3840\n",
      "        -------------------------\n",
      "        \n",
      "\n",
      "        -------------------------\n",
      "        ||||| ROUND 1 STATS |||||:\n",
      "        -------------------------\n",
      "        Epochs trained: 87\n",
      "        Best validation performance: -7.3840\n",
      "        -------------------------\n",
      "        \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validating:  11%|█▏        | 57/500 [00:09<01:10,  6.28it/s]\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FAILED: {'density_estimator': 'nsf', 'hidden_features': 64, 'num_transforms': 4} with error: \n",
      "Running combination 11/18: {'density_estimator': 'nsf', 'hidden_features': 128, 'num_transforms': 2}\n",
      " Neural network successfully converged after 72 epochs.\n",
      "        -------------------------\n",
      "        ||||| ROUND 1 STATS |||||:\n",
      "        -------------------------\n",
      "        Epochs trained: 72\n",
      "        Best validation performance: -7.1729\n",
      "        -------------------------\n",
      "        \n",
      "\n",
      "        -------------------------\n",
      "        ||||| ROUND 1 STATS |||||:\n",
      "        -------------------------\n",
      "        Epochs trained: 72\n",
      "        Best validation performance: -7.1729\n",
      "        -------------------------\n",
      "        \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validating: 100%|██████████| 500/500 [00:11<00:00, 43.63it/s]\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation mean R^2: 0.640, RMSE: 0.1153\n",
      "Running combination 12/18: {'density_estimator': 'nsf', 'hidden_features': 128, 'num_transforms': 4}\n",
      " Neural network successfully converged after 100 epochs.\n",
      "        -------------------------\n",
      "        ||||| ROUND 1 STATS |||||:\n",
      "        -------------------------\n",
      "        Epochs trained: 100\n",
      "        Best validation performance: -7.3888\n",
      "        -------------------------\n",
      "        \n",
      "\n",
      "        -------------------------\n",
      "        ||||| ROUND 1 STATS |||||:\n",
      "        -------------------------\n",
      "        Epochs trained: 100\n",
      "        Best validation performance: -7.3888\n",
      "        -------------------------\n",
      "        \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validating: 100%|██████████| 500/500 [00:11<00:00, 43.83it/s]\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation mean R^2: 0.592, RMSE: 0.1147\n",
      "Running combination 13/18: {'density_estimator': 'mdn', 'hidden_features': 32, 'num_transforms': 2}\n",
      " Neural network successfully converged after 167 epochs.\n",
      "        -------------------------\n",
      "        ||||| ROUND 1 STATS |||||:\n",
      "        -------------------------\n",
      "        Epochs trained: 167\n",
      "        Best validation performance: -6.8300\n",
      "        -------------------------\n",
      "        \n",
      "\n",
      "        -------------------------\n",
      "        ||||| ROUND 1 STATS |||||:\n",
      "        -------------------------\n",
      "        Epochs trained: 167\n",
      "        Best validation performance: -6.8300\n",
      "        -------------------------\n",
      "        \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validating:  66%|██████▌   | 328/500 [00:01<00:00, 194.80it/s]WARNING:root:Only 0.051% proposal samples are\n",
      "                    accepted. It may take a long time to collect the remaining\n",
      "                    -1 samples. Consider interrupting (Ctrl-C) and switching to\n",
      "                    `build_posterior(..., sample_with='mcmc')`.\n",
      "WARNING:root:Only 0.051% proposal samples are\n",
      "                    accepted. It may take a long time to collect the remaining\n",
      "                    -1 samples. Consider interrupting (Ctrl-C) and switching to\n",
      "                    `build_posterior(..., sample_with='mcmc')`.\n",
      "Validating:  88%|████████▊ | 438/500 [14:21:15<2:01:54, 117.98s/it]\n",
      "\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 24\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     23\u001b[0m     posterior \u001b[38;5;241m=\u001b[39m trainer\u001b[38;5;241m.\u001b[39mtrain()\n\u001b[0;32m---> 24\u001b[0m     r2_scores, _, _ \u001b[38;5;241m=\u001b[39m \u001b[43mtrainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvalidate\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     25\u001b[0m     mean_r2 \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mmean(r2_scores)\n\u001b[1;32m     26\u001b[0m     results\u001b[38;5;241m.\u001b[39mappend({\n\u001b[1;32m     27\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mparams,\n\u001b[1;32m     28\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmean_r2\u001b[39m\u001b[38;5;124m'\u001b[39m: mean_r2,\n\u001b[1;32m     29\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mr2_scores\u001b[39m\u001b[38;5;124m'\u001b[39m: r2_scores,\n\u001b[1;32m     30\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtimed_out\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m     31\u001b[0m     })\n",
      "File \u001b[0;32m~/sbi-DELTA/sbi_delta/trainer.py:104\u001b[0m, in \u001b[0;36mTrainer.validate\u001b[0;34m(self, n_samples)\u001b[0m\n\u001b[1;32m    102\u001b[0m posterior_width \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m    103\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m tqdm(\u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_val), desc\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mValidating\u001b[39m\u001b[38;5;124m'\u001b[39m, leave\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m):\n\u001b[0;32m--> 104\u001b[0m     samples \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mposterior\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msample\u001b[49m\u001b[43m(\u001b[49m\u001b[43m(\u001b[49m\u001b[43mn_samples\u001b[49m\u001b[43m,\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mval_x\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mshow_progress_bars\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m    105\u001b[0m     mean \u001b[38;5;241m=\u001b[39m samples\u001b[38;5;241m.\u001b[39mmean(dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\u001b[38;5;241m.\u001b[39mnumpy()\n\u001b[1;32m    106\u001b[0m     std \u001b[38;5;241m=\u001b[39m samples\u001b[38;5;241m.\u001b[39mstd(dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\u001b[38;5;241m.\u001b[39mnumpy()\n",
      "File \u001b[0;32m~/mambaforge/envs/sbi_env/lib/python3.10/site-packages/sbi/inference/posteriors/direct_posterior.py:134\u001b[0m, in \u001b[0;36mDirectPosterior.sample\u001b[0;34m(self, sample_shape, x, max_sampling_batch_size, sample_with, show_progress_bars)\u001b[0m\n\u001b[1;32m    127\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m sample_with \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    128\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    129\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mYou set `sample_with=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00msample_with\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m`. As of sbi v0.18.0, setting \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    130\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m`sample_with` is no longer supported. You have to rerun \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    131\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m`.build_posterior(sample_with=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00msample_with\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m).`\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    132\u001b[0m     )\n\u001b[0;32m--> 134\u001b[0m samples \u001b[38;5;241m=\u001b[39m \u001b[43mrejection\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43maccept_reject_sample\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    135\u001b[0m \u001b[43m    \u001b[49m\u001b[43mproposal\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mposterior_estimator\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msample\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    136\u001b[0m \u001b[43m    \u001b[49m\u001b[43maccept_reject_fn\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mlambda\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mtheta\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mwithin_support\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mprior\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtheta\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    137\u001b[0m \u001b[43m    \u001b[49m\u001b[43mnum_samples\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnum_samples\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    138\u001b[0m \u001b[43m    \u001b[49m\u001b[43mshow_progress_bars\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mshow_progress_bars\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    139\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmax_sampling_batch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmax_sampling_batch_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    140\u001b[0m \u001b[43m    \u001b[49m\u001b[43mproposal_sampling_kwargs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcondition\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    141\u001b[0m \u001b[43m    \u001b[49m\u001b[43malternative_method\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mbuild_posterior(..., sample_with=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mmcmc\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m)\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    142\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m[\u001b[38;5;241m0\u001b[39m]  \u001b[38;5;66;03m# [0] to return only samples, not acceptance probabilities.\u001b[39;00m\n\u001b[1;32m    144\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m samples[:, \u001b[38;5;241m0\u001b[39m]\n",
      "File \u001b[0;32m~/mambaforge/envs/sbi_env/lib/python3.10/site-packages/torch/utils/_contextlib.py:116\u001b[0m, in \u001b[0;36mcontext_decorator.<locals>.decorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    113\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mwraps(func)\n\u001b[1;32m    114\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mdecorate_context\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m    115\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m ctx_factory():\n\u001b[0;32m--> 116\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/mambaforge/envs/sbi_env/lib/python3.10/site-packages/sbi/samplers/rejection/rejection.py:283\u001b[0m, in \u001b[0;36maccept_reject_sample\u001b[0;34m(proposal, accept_reject_fn, num_samples, num_xos, show_progress_bars, warn_acceptance, sample_for_correction_factor, max_sampling_batch_size, proposal_sampling_kwargs, alternative_method, **kwargs)\u001b[0m\n\u001b[1;32m    280\u001b[0m num_samples_possible \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m    281\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m num_remaining \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m    282\u001b[0m     \u001b[38;5;66;03m# Sample and reject.\u001b[39;00m\n\u001b[0;32m--> 283\u001b[0m     candidates \u001b[38;5;241m=\u001b[39m \u001b[43mproposal\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    284\u001b[0m \u001b[43m        \u001b[49m\u001b[43m(\u001b[49m\u001b[43msampling_batch_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# type: ignore\u001b[39;49;00m\n\u001b[1;32m    285\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mproposal_sampling_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    286\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    287\u001b[0m     \u001b[38;5;66;03m# SNPE-style rejection-sampling when the proposal is the neural net.\u001b[39;00m\n\u001b[1;32m    288\u001b[0m     are_accepted \u001b[38;5;241m=\u001b[39m accept_reject_fn(candidates)\n",
      "File \u001b[0;32m~/mambaforge/envs/sbi_env/lib/python3.10/site-packages/sbi/neural_nets/estimators/nflows_flow.py:137\u001b[0m, in \u001b[0;36mNFlowsFlow.sample\u001b[0;34m(self, sample_shape, condition)\u001b[0m\n\u001b[1;32m    134\u001b[0m condition_batch_dim \u001b[38;5;241m=\u001b[39m condition\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m    135\u001b[0m num_samples \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mSize(sample_shape)\u001b[38;5;241m.\u001b[39mnumel()\n\u001b[0;32m--> 137\u001b[0m samples \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnet\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msample\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnum_samples\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcontext\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcondition\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    138\u001b[0m \u001b[38;5;66;03m# Change from Nflows' convention of (batch_dim, sample_dim, *event_shape) to\u001b[39;00m\n\u001b[1;32m    139\u001b[0m \u001b[38;5;66;03m# (sample_dim, batch_dim, *event_shape) (PyTorch + SBI).\u001b[39;00m\n\u001b[1;32m    140\u001b[0m samples \u001b[38;5;241m=\u001b[39m samples\u001b[38;5;241m.\u001b[39mtranspose(\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m1\u001b[39m)\n",
      "File \u001b[0;32m~/mambaforge/envs/sbi_env/lib/python3.10/site-packages/nflows/distributions/base.py:65\u001b[0m, in \u001b[0;36mDistribution.sample\u001b[0;34m(self, num_samples, context, batch_size)\u001b[0m\n\u001b[1;32m     62\u001b[0m     context \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mas_tensor(context)\n\u001b[1;32m     64\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m batch_size \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m---> 65\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_sample\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnum_samples\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcontext\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     67\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     68\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m check\u001b[38;5;241m.\u001b[39mis_positive_int(batch_size):\n",
      "File \u001b[0;32m~/mambaforge/envs/sbi_env/lib/python3.10/site-packages/nflows/flows/base.py:45\u001b[0m, in \u001b[0;36mFlow._sample\u001b[0;34m(self, num_samples, context)\u001b[0m\n\u001b[1;32m     43\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m_sample\u001b[39m(\u001b[38;5;28mself\u001b[39m, num_samples, context):\n\u001b[1;32m     44\u001b[0m     embedded_context \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_embedding_net(context)\n\u001b[0;32m---> 45\u001b[0m     noise \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_distribution\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msample\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnum_samples\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcontext\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43membedded_context\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     47\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m embedded_context \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m     48\u001b[0m         \u001b[38;5;66;03m# Merge the context dimension with sample dimension in order to apply the transform.\u001b[39;00m\n\u001b[1;32m     49\u001b[0m         noise \u001b[38;5;241m=\u001b[39m torchutils\u001b[38;5;241m.\u001b[39mmerge_leading_dims(noise, num_dims\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m)\n",
      "File \u001b[0;32m~/mambaforge/envs/sbi_env/lib/python3.10/site-packages/pyknos/mdn/mdn.py:268\u001b[0m, in \u001b[0;36mMultivariateGaussianMDN.sample\u001b[0;34m(self, num_samples, context)\u001b[0m\n\u001b[1;32m    252\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    253\u001b[0m \u001b[38;5;124;03mReturn num_samples independent samples from MoG(inputs | context).\u001b[39;00m\n\u001b[1;32m    254\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    264\u001b[0m \u001b[38;5;124;03m    dimension.\u001b[39;00m\n\u001b[1;32m    265\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    267\u001b[0m \u001b[38;5;66;03m# Get necessary quantities.\u001b[39;00m\n\u001b[0;32m--> 268\u001b[0m logits, means, _, _, precision_factors \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_mixture_components\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcontext\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    269\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msample_mog(num_samples, logits, means, precision_factors)\n",
      "File \u001b[0;32m~/mambaforge/envs/sbi_env/lib/python3.10/site-packages/pyknos/mdn/mdn.py:169\u001b[0m, in \u001b[0;36mMultivariateGaussianMDN.get_mixture_components\u001b[0;34m(self, context)\u001b[0m\n\u001b[1;32m    167\u001b[0m \u001b[38;5;66;03m# one dimensional feature does not involve upper triangular parameters\u001b[39;00m\n\u001b[1;32m    168\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_features \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m--> 169\u001b[0m     upper \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_upper_layer\u001b[49m(h)\u001b[38;5;241m.\u001b[39mview(\n\u001b[1;32m    170\u001b[0m         \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_components, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_upper_params\n\u001b[1;32m    171\u001b[0m     )\n\u001b[1;32m    172\u001b[0m     precision_factors[\u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_row_ix, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_column_ix] \u001b[38;5;241m=\u001b[39m upper\n\u001b[1;32m    174\u001b[0m \u001b[38;5;66;03m# Precisions are given by SIGMA^-1 = A^T A.\u001b[39;00m\n",
      "File \u001b[0;32m~/mambaforge/envs/sbi_env/lib/python3.10/site-packages/torch/nn/modules/module.py:1918\u001b[0m, in \u001b[0;36mModule.__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m   1909\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;241m=\u001b[39m OrderedDict()\n\u001b[1;32m   1911\u001b[0m \u001b[38;5;66;03m# On the return type:\u001b[39;00m\n\u001b[1;32m   1912\u001b[0m \u001b[38;5;66;03m# We choose to return `Any` in the `__getattr__` type signature instead of a more strict `Union[Tensor, Module]`.\u001b[39;00m\n\u001b[1;32m   1913\u001b[0m \u001b[38;5;66;03m# This is done for better interop with various type checkers for the end users.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1916\u001b[0m \u001b[38;5;66;03m# See full discussion on the problems with returning `Union` here\u001b[39;00m\n\u001b[1;32m   1917\u001b[0m \u001b[38;5;66;03m# https://github.com/microsoft/pyright/issues/4213\u001b[39;00m\n\u001b[0;32m-> 1918\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m__getattr__\u001b[39m(\u001b[38;5;28mself\u001b[39m, name: \u001b[38;5;28mstr\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Any:\n\u001b[1;32m   1919\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_parameters\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__dict__\u001b[39m:\n\u001b[1;32m   1920\u001b[0m         _parameters \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__dict__\u001b[39m[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_parameters\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Run Trainer for Each Architecture Parameter Combination (skip known slow config)\n",
    "results = []\n",
    "n_train = 2000  # Use a realistic value for architecture sweep\n",
    "n_val = 500\n",
    "SKIP_CONFIG = {'density_estimator': 'mdn', 'hidden_features': 32, 'num_transforms': 4}\n",
    "\n",
    "for i, params in enumerate(param_combinations):\n",
    "    if (params['density_estimator'] == SKIP_CONFIG['density_estimator'] and\n",
    "        params['hidden_features'] == SKIP_CONFIG['hidden_features'] and\n",
    "        params['num_transforms'] == SKIP_CONFIG['num_transforms']):\n",
    "        print(f\"SKIPPING: {params} (known slow configuration)\")\n",
    "        results.append({**params, 'mean_r2': None, 'r2_scores': None, 'timed_out': True})\n",
    "        continue\n",
    "    print(f\"Running combination {i+1}/{len(param_combinations)}: {params}\")\n",
    "    network_architecture = {\n",
    "        'density_estimator': params['density_estimator'],\n",
    "        'hidden_features': params['hidden_features'],\n",
    "        'num_transforms': params['num_transforms']\n",
    "    }\n",
    "    save_dir = f\"arch_sweep_run_{i}\"\n",
    "    trainer = Trainer(simulator, n_train=n_train, n_val=n_val, save_dir=save_dir, network_architecture=network_architecture)\n",
    "    try:\n",
    "        posterior = trainer.train()\n",
    "        r2_scores, _, _ = trainer.validate()\n",
    "        mean_r2 = np.mean(r2_scores)\n",
    "        results.append({\n",
    "            **params,\n",
    "            'mean_r2': mean_r2,\n",
    "            'r2_scores': r2_scores,\n",
    "            'timed_out': False\n",
    "        })\n",
    "    except Exception as e:\n",
    "        print(f\"FAILED: {params} with error: {e}\")\n",
    "        results.append({**params, 'mean_r2': None, 'r2_scores': None, 'timed_out': True})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1250e6bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Collect and Store R² Scores\n",
    "results_df = pd.DataFrame(results)\n",
    "results_df.sort_values('mean_r2', ascending=False, inplace=True)\n",
    "results_df.reset_index(drop=True, inplace=True)\n",
    "results_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d415f09e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize R² Score Improvements Across Architecture Parameters\n",
    "plt.figure(figsize=(12, 7))\n",
    "for de in param_grid['density_estimator']:\n",
    "    for nt in param_grid['num_transforms']:\n",
    "        subset = results_df[(results_df['density_estimator'] == de) & (results_df['num_transforms'] == nt)]\n",
    "        plt.plot(subset['hidden_features'], subset['mean_r2'], marker='o', label=f\"{de}, num_transforms={nt}\")\n",
    "plt.xlabel('Hidden Features')\n",
    "plt.ylabel('Mean R² Score')\n",
    "plt.title('Mean R² Score vs. Hidden Features for Each Architecture')\n",
    "plt.legend(title='Architecture (Density Estimator, Num Transforms)')\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b84a3714",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (sbi_env)",
   "language": "python",
   "name": "sbi_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
