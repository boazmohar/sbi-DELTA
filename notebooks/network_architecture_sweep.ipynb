{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "94b3629d",
   "metadata": {},
   "source": [
    "# Parameter Sweep for Network Architectures: R² Improvement Analysis\n",
    "\n",
    "This notebook performs a parameter sweep over different network architectures and hyperparameters for the SBI Trainer, using synthetic spectra. The goal is to identify which settings yield the best R² improvements."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8dcd7ad4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Required Libraries\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import itertools\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "\n",
    "from sbi_delta.trainer import Trainer\n",
    "from sbi_delta.simulator.emission_simulator import EmissionSimulator\n",
    "from sbi_delta.spectra_manager import SpectraManager\n",
    "from sbi_delta.filter_bank import FilterBank\n",
    "from sbi_delta.config import BaseConfig, FilterConfig, ExcitationConfig\n",
    "from sbi_delta.excitation_manager import ExcitationManager"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7742129d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set Up Real Data and Configuration (matching sbi_hyperparameter_search.ipynb)\n",
    "import os\n",
    "base_path = os.path.abspath(\".\")\n",
    "fluorophore_names = [\"JF479\", \"JF525\", \"JF552\", \"JF608\", \"JFX650\", \"JFX673\"]\n",
    "\n",
    "config = BaseConfig(\n",
    "    min_wavelength=400,\n",
    "    max_wavelength=750,\n",
    "    wavelength_step=1,\n",
    "    spectra_folder=os.path.join(base_path, \"data/spectra_npz\"),\n",
    "    dye_names=fluorophore_names,\n",
    "    bg_dye='AF_v1',\n",
    "    photon_budget=1000,\n",
    ")\n",
    "filter_cfgs = [\n",
    "    FilterConfig(start, stop, sharpness=1)\n",
    "    for start, stop in zip([490, 530, 570, 620, 680], [530, 570, 620, 680, 740])\n",
    "]\n",
    "excitation_cfg = ExcitationConfig(excitation_mode=\"min_crosstalk\")\n",
    "spectra_manager = SpectraManager(config)\n",
    "spectra_manager.load()\n",
    "excitation_manager = ExcitationManager(config, excitation_cfg, spectra_manager)\n",
    "filter_bank = FilterBank(config, filter_cfgs)\n",
    "simulator = EmissionSimulator(\n",
    "    spectra_manager=spectra_manager,\n",
    "    filter_bank=filter_bank,\n",
    "    config=config,\n",
    "    excitation_manager=excitation_manager\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f20711ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total architecture parameter combinations: 18\n"
     ]
    }
   ],
   "source": [
    "# Define Architecture Parameter Sweep Grid\n",
    "# Sweep only over network architecture (density estimator, hidden features, num transforms)\n",
    "param_grid = {\n",
    "    'density_estimator': ['maf', 'nsf', 'mdn'],\n",
    "    'hidden_features': [32, 64, 128],\n",
    "    'num_transforms': [2, 4]\n",
    "}\n",
    "\n",
    "# Create all combinations\n",
    "keys, values = zip(*param_grid.items())\n",
    "param_combinations = [dict(zip(keys, v)) for v in itertools.product(*values)]\n",
    "print(f\"Total architecture parameter combinations: {len(param_combinations)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "631b3623",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running combination 1/18: {'density_estimator': 'maf', 'hidden_features': 32, 'num_transforms': 2}\n",
      " Neural network successfully converged after 172 epochs.\n",
      "        -------------------------\n",
      "        ||||| ROUND 1 STATS |||||:\n",
      "        -------------------------\n",
      "        Epochs trained: 172\n",
      "        Best validation performance: -7.7921\n",
      "        -------------------------\n",
      "        \n",
      "\n",
      "        -------------------------\n",
      "        ||||| ROUND 1 STATS |||||:\n",
      "        -------------------------\n",
      "        Epochs trained: 172\n",
      "        Best validation performance: -7.7921\n",
      "        -------------------------\n",
      "        \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validating: 100%|██████████| 500/500 [00:13<00:00, 37.39it/s]\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation mean R^2: 0.630, RMSE: 0.1127\n",
      "Running combination 2/18: {'density_estimator': 'maf', 'hidden_features': 32, 'num_transforms': 4}\n",
      " Neural network successfully converged after 125 epochs.\n",
      "        -------------------------\n",
      "        ||||| ROUND 1 STATS |||||:\n",
      "        -------------------------\n",
      "        Epochs trained: 125\n",
      "        Best validation performance: -7.2994\n",
      "        -------------------------\n",
      "        \n",
      "\n",
      "        -------------------------\n",
      "        ||||| ROUND 1 STATS |||||:\n",
      "        -------------------------\n",
      "        Epochs trained: 125\n",
      "        Best validation performance: -7.2994\n",
      "        -------------------------\n",
      "        \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validating: 100%|██████████| 500/500 [00:14<00:00, 35.28it/s]\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation mean R^2: 0.648, RMSE: 0.1141\n",
      "Running combination 3/18: {'density_estimator': 'maf', 'hidden_features': 64, 'num_transforms': 2}\n",
      " Neural network successfully converged after 131 epochs.\n",
      "        -------------------------\n",
      "        ||||| ROUND 1 STATS |||||:\n",
      "        -------------------------\n",
      "        Epochs trained: 131\n",
      "        Best validation performance: -7.2718\n",
      "        -------------------------\n",
      "        \n",
      "\n",
      "        -------------------------\n",
      "        ||||| ROUND 1 STATS |||||:\n",
      "        -------------------------\n",
      "        Epochs trained: 131\n",
      "        Best validation performance: -7.2718\n",
      "        -------------------------\n",
      "        \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validating: 100%|██████████| 500/500 [00:14<00:00, 35.69it/s]\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation mean R^2: 0.615, RMSE: 0.1203\n",
      "Running combination 4/18: {'density_estimator': 'maf', 'hidden_features': 64, 'num_transforms': 4}\n",
      " Neural network successfully converged after 132 epochs.\n",
      "        -------------------------\n",
      "        ||||| ROUND 1 STATS |||||:\n",
      "        -------------------------\n",
      "        Epochs trained: 132\n",
      "        Best validation performance: -7.2259\n",
      "        -------------------------\n",
      "        \n",
      "\n",
      "        -------------------------\n",
      "        ||||| ROUND 1 STATS |||||:\n",
      "        -------------------------\n",
      "        Epochs trained: 132\n",
      "        Best validation performance: -7.2259\n",
      "        -------------------------\n",
      "        \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validating: 100%|██████████| 500/500 [00:13<00:00, 36.41it/s]\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation mean R^2: 0.694, RMSE: 0.1120\n",
      "Running combination 5/18: {'density_estimator': 'maf', 'hidden_features': 128, 'num_transforms': 2}\n",
      " Neural network successfully converged after 138 epochs.\n",
      "        -------------------------\n",
      "        ||||| ROUND 1 STATS |||||:\n",
      "        -------------------------\n",
      "        Epochs trained: 138\n",
      "        Best validation performance: -7.6644\n",
      "        -------------------------\n",
      "        \n",
      "\n",
      "        -------------------------\n",
      "        ||||| ROUND 1 STATS |||||:\n",
      "        -------------------------\n",
      "        Epochs trained: 138\n",
      "        Best validation performance: -7.6644\n",
      "        -------------------------\n",
      "        \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validating: 100%|██████████| 500/500 [00:13<00:00, 37.45it/s]\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation mean R^2: 0.685, RMSE: 0.1119\n",
      "Running combination 6/18: {'density_estimator': 'maf', 'hidden_features': 128, 'num_transforms': 4}\n",
      " Neural network successfully converged after 135 epochs.\n",
      "        -------------------------\n",
      "        ||||| ROUND 1 STATS |||||:\n",
      "        -------------------------\n",
      "        Epochs trained: 135\n",
      "        Best validation performance: -7.3980\n",
      "        -------------------------\n",
      "        \n",
      "\n",
      "        -------------------------\n",
      "        ||||| ROUND 1 STATS |||||:\n",
      "        -------------------------\n",
      "        Epochs trained: 135\n",
      "        Best validation performance: -7.3980\n",
      "        -------------------------\n",
      "        \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validating: 100%|██████████| 500/500 [00:13<00:00, 35.82it/s]\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation mean R^2: 0.636, RMSE: 0.1209\n",
      "Running combination 7/18: {'density_estimator': 'nsf', 'hidden_features': 32, 'num_transforms': 2}\n",
      " Neural network successfully converged after 75 epochs.\n",
      "        -------------------------\n",
      "        ||||| ROUND 1 STATS |||||:\n",
      "        -------------------------\n",
      "        Epochs trained: 75\n",
      "        Best validation performance: -7.0412\n",
      "        -------------------------\n",
      "        \n",
      "\n",
      "        -------------------------\n",
      "        ||||| ROUND 1 STATS |||||:\n",
      "        -------------------------\n",
      "        Epochs trained: 75\n",
      "        Best validation performance: -7.0412\n",
      "        -------------------------\n",
      "        \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validating:   0%|          | 0/500 [00:00<?, ?it/s]/groups/spruston/home/moharb/mambaforge/envs/sbi_env/lib/python3.10/site-packages/nflows/transforms/lu.py:80: UserWarning: torch.triangular_solve is deprecated in favor of torch.linalg.solve_triangularand will be removed in a future PyTorch release.\n",
      "torch.linalg.solve_triangular has its arguments reversed and does not return a copy of one of the inputs.\n",
      "X = torch.triangular_solve(B, A).solution\n",
      "should be replaced with\n",
      "X = torch.linalg.solve_triangular(A, B). (Triggered internally at ../aten/src/ATen/native/BatchLinearAlgebra.cpp:2190.)\n",
      "  outputs, _ = torch.triangular_solve(\n",
      "Validating:   1%|          | 5/500 [00:00<00:11, 42.41it/s]/groups/spruston/home/moharb/mambaforge/envs/sbi_env/lib/python3.10/site-packages/nflows/transforms/lu.py:80: UserWarning: torch.triangular_solve is deprecated in favor of torch.linalg.solve_triangularand will be removed in a future PyTorch release.\n",
      "torch.linalg.solve_triangular has its arguments reversed and does not return a copy of one of the inputs.\n",
      "X = torch.triangular_solve(B, A).solution\n",
      "should be replaced with\n",
      "X = torch.linalg.solve_triangular(A, B). (Triggered internally at ../aten/src/ATen/native/BatchLinearAlgebra.cpp:2190.)\n",
      "  outputs, _ = torch.triangular_solve(\n",
      "Validating: 100%|██████████| 500/500 [00:11<00:00, 44.22it/s]\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation mean R^2: 0.565, RMSE: 0.1251\n",
      "Running combination 8/18: {'density_estimator': 'nsf', 'hidden_features': 32, 'num_transforms': 4}\n",
      " Neural network successfully converged after 80 epochs.\n",
      "        -------------------------\n",
      "        ||||| ROUND 1 STATS |||||:\n",
      "        -------------------------\n",
      "        Epochs trained: 80\n",
      "        Best validation performance: -7.2948\n",
      "        -------------------------\n",
      "        \n",
      "\n",
      "        -------------------------\n",
      "        ||||| ROUND 1 STATS |||||:\n",
      "        -------------------------\n",
      "        Epochs trained: 80\n",
      "        Best validation performance: -7.2948\n",
      "        -------------------------\n",
      "        \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validating:  72%|███████▏  | 362/500 [03:39<01:23,  1.65it/s]\n",
      "\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 28\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     27\u001b[0m     posterior \u001b[38;5;241m=\u001b[39m trainer\u001b[38;5;241m.\u001b[39mtrain()\n\u001b[0;32m---> 28\u001b[0m     r2_scores, _, _ \u001b[38;5;241m=\u001b[39m \u001b[43mtrainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvalidate\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     29\u001b[0m     mean_r2 \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mmean(r2_scores)\n\u001b[1;32m     30\u001b[0m     results\u001b[38;5;241m.\u001b[39mappend({\n\u001b[1;32m     31\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mparams,\n\u001b[1;32m     32\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmean_r2\u001b[39m\u001b[38;5;124m'\u001b[39m: mean_r2,\n\u001b[1;32m     33\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mr2_scores\u001b[39m\u001b[38;5;124m'\u001b[39m: r2_scores,\n\u001b[1;32m     34\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtimed_out\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m     35\u001b[0m     })\n",
      "File \u001b[0;32m~/sbi-DELTA/sbi_delta/trainer.py:104\u001b[0m, in \u001b[0;36mTrainer.validate\u001b[0;34m(self, n_samples)\u001b[0m\n\u001b[1;32m    102\u001b[0m posterior_width \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m    103\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m tqdm(\u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_val), desc\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mValidating\u001b[39m\u001b[38;5;124m'\u001b[39m, leave\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m):\n\u001b[0;32m--> 104\u001b[0m     samples \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mposterior\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msample\u001b[49m\u001b[43m(\u001b[49m\u001b[43m(\u001b[49m\u001b[43mn_samples\u001b[49m\u001b[43m,\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mval_x\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mshow_progress_bars\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m    105\u001b[0m     mean \u001b[38;5;241m=\u001b[39m samples\u001b[38;5;241m.\u001b[39mmean(dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\u001b[38;5;241m.\u001b[39mnumpy()\n\u001b[1;32m    106\u001b[0m     std \u001b[38;5;241m=\u001b[39m samples\u001b[38;5;241m.\u001b[39mstd(dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\u001b[38;5;241m.\u001b[39mnumpy()\n",
      "File \u001b[0;32m~/mambaforge/envs/sbi_env/lib/python3.10/site-packages/sbi/inference/posteriors/direct_posterior.py:134\u001b[0m, in \u001b[0;36mDirectPosterior.sample\u001b[0;34m(self, sample_shape, x, max_sampling_batch_size, sample_with, show_progress_bars)\u001b[0m\n\u001b[1;32m    127\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m sample_with \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    128\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    129\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mYou set `sample_with=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00msample_with\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m`. As of sbi v0.18.0, setting \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    130\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m`sample_with` is no longer supported. You have to rerun \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    131\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m`.build_posterior(sample_with=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00msample_with\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m).`\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    132\u001b[0m     )\n\u001b[0;32m--> 134\u001b[0m samples \u001b[38;5;241m=\u001b[39m \u001b[43mrejection\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43maccept_reject_sample\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    135\u001b[0m \u001b[43m    \u001b[49m\u001b[43mproposal\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mposterior_estimator\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msample\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    136\u001b[0m \u001b[43m    \u001b[49m\u001b[43maccept_reject_fn\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mlambda\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mtheta\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mwithin_support\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mprior\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtheta\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    137\u001b[0m \u001b[43m    \u001b[49m\u001b[43mnum_samples\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnum_samples\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    138\u001b[0m \u001b[43m    \u001b[49m\u001b[43mshow_progress_bars\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mshow_progress_bars\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    139\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmax_sampling_batch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmax_sampling_batch_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    140\u001b[0m \u001b[43m    \u001b[49m\u001b[43mproposal_sampling_kwargs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcondition\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    141\u001b[0m \u001b[43m    \u001b[49m\u001b[43malternative_method\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mbuild_posterior(..., sample_with=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mmcmc\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m)\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    142\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m[\u001b[38;5;241m0\u001b[39m]  \u001b[38;5;66;03m# [0] to return only samples, not acceptance probabilities.\u001b[39;00m\n\u001b[1;32m    144\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m samples[:, \u001b[38;5;241m0\u001b[39m]\n",
      "File \u001b[0;32m~/mambaforge/envs/sbi_env/lib/python3.10/site-packages/torch/utils/_contextlib.py:116\u001b[0m, in \u001b[0;36mcontext_decorator.<locals>.decorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    113\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mwraps(func)\n\u001b[1;32m    114\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mdecorate_context\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m    115\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m ctx_factory():\n\u001b[0;32m--> 116\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/mambaforge/envs/sbi_env/lib/python3.10/site-packages/sbi/samplers/rejection/rejection.py:283\u001b[0m, in \u001b[0;36maccept_reject_sample\u001b[0;34m(proposal, accept_reject_fn, num_samples, num_xos, show_progress_bars, warn_acceptance, sample_for_correction_factor, max_sampling_batch_size, proposal_sampling_kwargs, alternative_method, **kwargs)\u001b[0m\n\u001b[1;32m    280\u001b[0m num_samples_possible \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m    281\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m num_remaining \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m    282\u001b[0m     \u001b[38;5;66;03m# Sample and reject.\u001b[39;00m\n\u001b[0;32m--> 283\u001b[0m     candidates \u001b[38;5;241m=\u001b[39m \u001b[43mproposal\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    284\u001b[0m \u001b[43m        \u001b[49m\u001b[43m(\u001b[49m\u001b[43msampling_batch_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# type: ignore\u001b[39;49;00m\n\u001b[1;32m    285\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mproposal_sampling_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    286\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    287\u001b[0m     \u001b[38;5;66;03m# SNPE-style rejection-sampling when the proposal is the neural net.\u001b[39;00m\n\u001b[1;32m    288\u001b[0m     are_accepted \u001b[38;5;241m=\u001b[39m accept_reject_fn(candidates)\n",
      "File \u001b[0;32m~/mambaforge/envs/sbi_env/lib/python3.10/site-packages/sbi/neural_nets/estimators/nflows_flow.py:137\u001b[0m, in \u001b[0;36mNFlowsFlow.sample\u001b[0;34m(self, sample_shape, condition)\u001b[0m\n\u001b[1;32m    134\u001b[0m condition_batch_dim \u001b[38;5;241m=\u001b[39m condition\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m    135\u001b[0m num_samples \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mSize(sample_shape)\u001b[38;5;241m.\u001b[39mnumel()\n\u001b[0;32m--> 137\u001b[0m samples \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnet\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msample\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnum_samples\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcontext\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcondition\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    138\u001b[0m \u001b[38;5;66;03m# Change from Nflows' convention of (batch_dim, sample_dim, *event_shape) to\u001b[39;00m\n\u001b[1;32m    139\u001b[0m \u001b[38;5;66;03m# (sample_dim, batch_dim, *event_shape) (PyTorch + SBI).\u001b[39;00m\n\u001b[1;32m    140\u001b[0m samples \u001b[38;5;241m=\u001b[39m samples\u001b[38;5;241m.\u001b[39mtranspose(\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m1\u001b[39m)\n",
      "File \u001b[0;32m~/mambaforge/envs/sbi_env/lib/python3.10/site-packages/nflows/distributions/base.py:65\u001b[0m, in \u001b[0;36mDistribution.sample\u001b[0;34m(self, num_samples, context, batch_size)\u001b[0m\n\u001b[1;32m     62\u001b[0m     context \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mas_tensor(context)\n\u001b[1;32m     64\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m batch_size \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m---> 65\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_sample\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnum_samples\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcontext\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     67\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     68\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m check\u001b[38;5;241m.\u001b[39mis_positive_int(batch_size):\n",
      "File \u001b[0;32m~/mambaforge/envs/sbi_env/lib/python3.10/site-packages/nflows/flows/base.py:54\u001b[0m, in \u001b[0;36mFlow._sample\u001b[0;34m(self, num_samples, context)\u001b[0m\n\u001b[1;32m     49\u001b[0m     noise \u001b[38;5;241m=\u001b[39m torchutils\u001b[38;5;241m.\u001b[39mmerge_leading_dims(noise, num_dims\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m)\n\u001b[1;32m     50\u001b[0m     embedded_context \u001b[38;5;241m=\u001b[39m torchutils\u001b[38;5;241m.\u001b[39mrepeat_rows(\n\u001b[1;32m     51\u001b[0m         embedded_context, num_reps\u001b[38;5;241m=\u001b[39mnum_samples\n\u001b[1;32m     52\u001b[0m     )\n\u001b[0;32m---> 54\u001b[0m samples, _ \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_transform\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minverse\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnoise\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcontext\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43membedded_context\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     56\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m embedded_context \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m     57\u001b[0m     \u001b[38;5;66;03m# Split the context dimension from sample dimension.\u001b[39;00m\n\u001b[1;32m     58\u001b[0m     samples \u001b[38;5;241m=\u001b[39m torchutils\u001b[38;5;241m.\u001b[39msplit_leading_dim(samples, shape\u001b[38;5;241m=\u001b[39m[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, num_samples])\n",
      "File \u001b[0;32m~/mambaforge/envs/sbi_env/lib/python3.10/site-packages/nflows/transforms/base.py:60\u001b[0m, in \u001b[0;36mCompositeTransform.inverse\u001b[0;34m(self, inputs, context)\u001b[0m\n\u001b[1;32m     58\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21minverse\u001b[39m(\u001b[38;5;28mself\u001b[39m, inputs, context\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[1;32m     59\u001b[0m     funcs \u001b[38;5;241m=\u001b[39m (transform\u001b[38;5;241m.\u001b[39minverse \u001b[38;5;28;01mfor\u001b[39;00m transform \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_transforms[::\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m])\n\u001b[0;32m---> 60\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_cascade\u001b[49m\u001b[43m(\u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfuncs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcontext\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/mambaforge/envs/sbi_env/lib/python3.10/site-packages/nflows/transforms/base.py:50\u001b[0m, in \u001b[0;36mCompositeTransform._cascade\u001b[0;34m(inputs, funcs, context)\u001b[0m\n\u001b[1;32m     48\u001b[0m total_logabsdet \u001b[38;5;241m=\u001b[39m inputs\u001b[38;5;241m.\u001b[39mnew_zeros(batch_size)\n\u001b[1;32m     49\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m func \u001b[38;5;129;01min\u001b[39;00m funcs:\n\u001b[0;32m---> 50\u001b[0m     outputs, logabsdet \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43moutputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcontext\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     51\u001b[0m     total_logabsdet \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m logabsdet\n\u001b[1;32m     52\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m outputs, total_logabsdet\n",
      "File \u001b[0;32m~/mambaforge/envs/sbi_env/lib/python3.10/site-packages/nflows/transforms/coupling.py:119\u001b[0m, in \u001b[0;36mCouplingTransform.inverse\u001b[0;34m(self, inputs, context)\u001b[0m\n\u001b[1;32m    114\u001b[0m     identity_split, logabsdet \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39munconditional_transform\u001b[38;5;241m.\u001b[39minverse(\n\u001b[1;32m    115\u001b[0m         identity_split, context\n\u001b[1;32m    116\u001b[0m     )\n\u001b[1;32m    118\u001b[0m transform_params \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtransform_net(identity_split, context)\n\u001b[0;32m--> 119\u001b[0m transform_split, logabsdet_split \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_coupling_transform_inverse\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    120\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtransform_split\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtransform_params\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtransform_params\u001b[49m\n\u001b[1;32m    121\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    122\u001b[0m logabsdet \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m logabsdet_split\n\u001b[1;32m    124\u001b[0m outputs \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mempty_like(inputs)\n",
      "File \u001b[0;32m~/mambaforge/envs/sbi_env/lib/python3.10/site-packages/nflows/transforms/coupling.py:197\u001b[0m, in \u001b[0;36mPiecewiseCouplingTransform._coupling_transform_inverse\u001b[0;34m(self, inputs, transform_params)\u001b[0m\n\u001b[1;32m    196\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m_coupling_transform_inverse\u001b[39m(\u001b[38;5;28mself\u001b[39m, inputs, transform_params):\n\u001b[0;32m--> 197\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_coupling_transform\u001b[49m\u001b[43m(\u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtransform_params\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minverse\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/mambaforge/envs/sbi_env/lib/python3.10/site-packages/nflows/transforms/coupling.py:211\u001b[0m, in \u001b[0;36mPiecewiseCouplingTransform._coupling_transform\u001b[0;34m(self, inputs, transform_params, inverse)\u001b[0m\n\u001b[1;32m    208\u001b[0m     \u001b[38;5;66;03m# For 2D data, reshape transform_params from Bx(D*?) to BxDx?\u001b[39;00m\n\u001b[1;32m    209\u001b[0m     transform_params \u001b[38;5;241m=\u001b[39m transform_params\u001b[38;5;241m.\u001b[39mreshape(b, d, \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m--> 211\u001b[0m outputs, logabsdet \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_piecewise_cdf\u001b[49m\u001b[43m(\u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtransform_params\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minverse\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    213\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m outputs, torchutils\u001b[38;5;241m.\u001b[39msum_except_batch(logabsdet)\n",
      "File \u001b[0;32m~/mambaforge/envs/sbi_env/lib/python3.10/site-packages/nflows/transforms/coupling.py:492\u001b[0m, in \u001b[0;36mPiecewiseRationalQuadraticCouplingTransform._piecewise_cdf\u001b[0;34m(self, inputs, transform_params, inverse)\u001b[0m\n\u001b[1;32m    489\u001b[0m     spline_fn \u001b[38;5;241m=\u001b[39m splines\u001b[38;5;241m.\u001b[39munconstrained_rational_quadratic_spline\n\u001b[1;32m    490\u001b[0m     spline_kwargs \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtails\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtails, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtail_bound\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtail_bound}\n\u001b[0;32m--> 492\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mspline_fn\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    493\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    494\u001b[0m \u001b[43m    \u001b[49m\u001b[43munnormalized_widths\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43munnormalized_widths\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    495\u001b[0m \u001b[43m    \u001b[49m\u001b[43munnormalized_heights\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43munnormalized_heights\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    496\u001b[0m \u001b[43m    \u001b[49m\u001b[43munnormalized_derivatives\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43munnormalized_derivatives\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    497\u001b[0m \u001b[43m    \u001b[49m\u001b[43minverse\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minverse\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    498\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmin_bin_width\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmin_bin_width\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    499\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmin_bin_height\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmin_bin_height\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    500\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmin_derivative\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmin_derivative\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    501\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mspline_kwargs\u001b[49m\n\u001b[1;32m    502\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Run Trainer for Each Architecture Parameter Combination (skip known slow config)\n",
    "results = []\n",
    "n_train = 2000  # Use a realistic value for architecture sweep\n",
    "n_val = 500\n",
    "SKIP_CONFIG = {'density_estimator': 'mdn', 'hidden_features': 32, 'num_transforms': 4}\n",
    "\n",
    "for i, params in enumerate(param_combinations):\n",
    "    if (params['density_estimator'] == SKIP_CONFIG['density_estimator'] and\n",
    "        params['hidden_features'] == SKIP_CONFIG['hidden_features'] and\n",
    "        params['num_transforms'] == SKIP_CONFIG['num_transforms']):\n",
    "        print(f\"SKIPPING: {params} (known slow configuration)\")\n",
    "        results.append({**params, 'mean_r2': None, 'r2_scores': None, 'timed_out': True})\n",
    "        continue\n",
    "    print(f\"Running combination {i+1}/{len(param_combinations)}: {params}\")\n",
    "    network_architecture = {\n",
    "        'density_estimator': params['density_estimator'],\n",
    "        'hidden_features': params['hidden_features'],\n",
    "        'num_transforms': params['num_transforms']\n",
    "    }\n",
    "    save_dir = f\"arch_sweep_run_{i}\"\n",
    "    trainer = Trainer(simulator, n_train=n_train, n_val=n_val, save_dir=save_dir, network_architecture=network_architecture)\n",
    "    try:\n",
    "        posterior = trainer.train()\n",
    "        r2_scores, _, _ = trainer.validate()\n",
    "        mean_r2 = np.mean(r2_scores)\n",
    "        results.append({\n",
    "            **params,\n",
    "            'mean_r2': mean_r2,\n",
    "            'r2_scores': r2_scores,\n",
    "            'timed_out': False\n",
    "        })\n",
    "    except Exception as e:\n",
    "        print(f\"FAILED: {params} with error: {e}\")\n",
    "        results.append({**params, 'mean_r2': None, 'r2_scores': None, 'timed_out': True})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1250e6bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Collect and Store R² Scores\n",
    "results_df = pd.DataFrame(results)\n",
    "results_df.sort_values('mean_r2', ascending=False, inplace=True)\n",
    "results_df.reset_index(drop=True, inplace=True)\n",
    "results_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d415f09e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize R² Score Improvements Across Architecture Parameters\n",
    "plt.figure(figsize=(12, 7))\n",
    "for de in param_grid['density_estimator']:\n",
    "    for nt in param_grid['num_transforms']:\n",
    "        subset = results_df[(results_df['density_estimator'] == de) & (results_df['num_transforms'] == nt)]\n",
    "        plt.plot(subset['hidden_features'], subset['mean_r2'], marker='o', label=f\"{de}, num_transforms={nt}\")\n",
    "plt.xlabel('Hidden Features')\n",
    "plt.ylabel('Mean R² Score')\n",
    "plt.title('Mean R² Score vs. Hidden Features for Each Architecture')\n",
    "plt.legend(title='Architecture (Density Estimator, Num Transforms)')\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (sbi_env)",
   "language": "python",
   "name": "sbi_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
